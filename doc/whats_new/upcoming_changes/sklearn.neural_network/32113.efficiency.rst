- :class:`neural_network.MLPClassifier` and :class:`neural_network.MLPRegressor`
  now use in-place NumPy operations in their stochastic optimizers (SGD and Adam),
  avoiding memory allocations and resulting in approximately 20-25% performance
  improvement for neural network training.
  By :user:`Devarshi <codeMaestro78>`
